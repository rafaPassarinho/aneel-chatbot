{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "37917bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo ../data/atren20211000.pdf j√° existe. Usando arquivo local.\n",
      "\n",
      "=== Testing Comprehensive Parsing ===\n",
      "Processando PDF: ../data/atren20211000.pdf com 314 p√°ginas.\n",
      "Total de chunks processados: 549\n",
      "Total chunks extracted: 549\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import re\n",
    "import requests\n",
    "import os\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "PDF_URL = \"https://www2.aneel.gov.br/cedoc/atren20211000.pdf\"\n",
    "LOCAL_PDF_PATH = r\"../data/atren20211000.pdf\"\n",
    "\n",
    "# Document metadata\n",
    "DOC_INFO_DEFAULTS = {\n",
    "    \"source_document_url\": PDF_URL,\n",
    "    \"source_document_name\": LOCAL_PDF_PATH,\n",
    "    \"document_type\": \"Resolu√ß√£o Normativa\",\n",
    "    \"issuer\": \"ANEEL\"\n",
    "}\n",
    "\n",
    "# Optimized patterns based on actual PDF structure\n",
    "PATTERNS = {\n",
    "    \"titulo\": re.compile(r\"^\\s*T[√çI]TULO\\s+([IVXLCDM]+)\\s*$\", re.IGNORECASE),\n",
    "    \"capitulo\": re.compile(r\"^\\s*CAP[√çI]TULO\\s+([IVXLCDM]+)\\s*$\", re.IGNORECASE),\n",
    "    \"secao\": re.compile(r\"^\\s*(?:SUB)?[Ss]e[√ßc][√£a]o\\s+([IVXLCDM]+)\\s*$\", re.IGNORECASE),\n",
    "    \"artigo_start\": re.compile(r\"^\\s*Art\\.\\s*(\\d+(?:[A-Za-z])?¬∫?)\\s+(.*)\", re.IGNORECASE),\n",
    "    \"paragrafo_start\": re.compile(r\"^\\s*¬ß\\s*(\\d+¬∫?|√∫nico)\\s+(.+)\", re.IGNORECASE),\n",
    "    \"inciso_start\": re.compile(r\"^\\s*([IVXLCDM]+(?:-[A-Z])?)\\s*-\\s*(.+)\"),\n",
    "    \"alinea_start\": re.compile(r\"^\\s*([a-z])\\)\\s*(.+)\")\n",
    "}\n",
    "\n",
    "def clean_text_line(text: str) -> str:\n",
    "    \"\"\"Clean text by replacing special characters and normalizing whitespace.\"\"\"\n",
    "    replacements = {\n",
    "        '\\xa0': ' ',  # Non-breaking space\n",
    "        '\\xad': '',   # Soft hyphen\n",
    "        '\\u2013': '-', # En dash\n",
    "        '\\u2014': '-'  # Em dash\n",
    "    }\n",
    "    for k, v in replacements.items():\n",
    "        text = text.replace(k, v)\n",
    "    return text.strip()\n",
    "\n",
    "def download_pdf_if_not_exists(url: str, local_path: str) -> bool:\n",
    "    \"\"\"Download PDF if it doesn't exist locally.\"\"\"\n",
    "    if os.path.exists(local_path):\n",
    "        print(f\"Arquivo {local_path} j√° existe. Usando arquivo local.\")\n",
    "        return True\n",
    "    \n",
    "    print(f\"Baixando PDF de {url} para {local_path}...\")\n",
    "    try:\n",
    "        response = requests.get(url, stream=True, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        with open(local_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        print(f\"PDF baixado com sucesso: {local_path}\")\n",
    "        return True\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Erro ao baixar o PDF: {e}\")\n",
    "        return False\n",
    "\n",
    "def build_full_hierarchical_path(metadata_dict: dict) -> str:\n",
    "    \"\"\"Build complete hierarchical path from metadata dictionary.\"\"\"\n",
    "    components = [\n",
    "        metadata_dict.get(\"titulo_text\"),\n",
    "        metadata_dict.get(\"capitulo_text\"),\n",
    "        metadata_dict.get(\"secao_text\"),\n",
    "        metadata_dict.get(\"artigo_number\"),\n",
    "    ]\n",
    "    return \" > \".join(filter(None, components))\n",
    "\n",
    "def parse_aneel_pdf(\n",
    "        pdf_path: str,\n",
    "        max_chunk_size: int = 1500,\n",
    "        chunk_overlap: int = 200\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Comprehensive parsing that captures ALL content and properly tracks hierarchy.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(pdf_path):\n",
    "        raise FileNotFoundError(f\"Arquivo PDF n√£o encontrado: {pdf_path}\")\n",
    "    \n",
    "    all_chunks = []\n",
    "    current_hierarchy = {\n",
    "        \"titulo_text\": None,\n",
    "        \"capitulo_text\": None,\n",
    "        \"secao_text\": None,\n",
    "        \"artigo_number\": None\n",
    "    }\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=max_chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \"; \", \" \", \"\"],\n",
    "        strip_whitespace=True\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        print(f\"Processando PDF: {pdf_path} com {len(doc)} p√°ginas.\")\n",
    "\n",
    "        # First pass: track hierarchy as we go through the document\n",
    "        full_text_with_hierarchy = []\n",
    "        \n",
    "        for page_num, page in enumerate(doc, 1):\n",
    "            page_text = page.get_text()\n",
    "            if not page_text.strip():\n",
    "                continue\n",
    "                \n",
    "            lines = page_text.split('\\n')\n",
    "            for line in lines:\n",
    "                line_clean = clean_text_line(line).strip()\n",
    "                if not line_clean:\n",
    "                    continue\n",
    "                \n",
    "                # Check for hierarchy updates\n",
    "                titulo_match = PATTERNS[\"titulo\"].match(line_clean)\n",
    "                capitulo_match = PATTERNS[\"capitulo\"].match(line_clean)\n",
    "                secao_match = PATTERNS[\"secao\"].match(line_clean)\n",
    "                artigo_match = PATTERNS[\"artigo_start\"].match(line_clean)\n",
    "                \n",
    "                if titulo_match:\n",
    "                    current_hierarchy.update({\n",
    "                        \"titulo_text\": f\"T√çTULO {titulo_match.group(1)}\",\n",
    "                        \"capitulo_text\": None,\n",
    "                        \"secao_text\": None,\n",
    "                        \"artigo_number\": None\n",
    "                    })\n",
    "                elif capitulo_match:\n",
    "                    current_hierarchy.update({\n",
    "                        \"capitulo_text\": f\"CAP√çTULO {capitulo_match.group(1)}\",\n",
    "                        \"secao_text\": None,\n",
    "                        \"artigo_number\": None\n",
    "                    })\n",
    "                elif secao_match:\n",
    "                    current_hierarchy.update({\n",
    "                        \"secao_text\": f\"Se√ß√£o {secao_match.group(1)}\",\n",
    "                        \"artigo_number\": None\n",
    "                    })\n",
    "                elif artigo_match:\n",
    "                    current_hierarchy[\"artigo_number\"] = f\"Art. {artigo_match.group(1)}\"\n",
    "                \n",
    "                # Store text with current hierarchy context\n",
    "                full_text_with_hierarchy.append({\n",
    "                    \"text\": line_clean,\n",
    "                    \"page\": page_num,\n",
    "                    \"hierarchy\": current_hierarchy.copy()  # Important: copy the dict\n",
    "                })\n",
    "        \n",
    "        # Second pass: create chunks with proper hierarchy metadata\n",
    "        all_text = \"\\n\".join([item[\"text\"] for item in full_text_with_hierarchy])\n",
    "        text_chunks = text_splitter.split_text(all_text)\n",
    "        \n",
    "        for idx, chunk in enumerate(text_chunks):\n",
    "            # Find the most relevant hierarchy for this chunk\n",
    "            chunk_metadata = DOC_INFO_DEFAULTS.copy()\n",
    "            \n",
    "            # Look for hierarchy elements in the chunk text\n",
    "            best_hierarchy = {\"titulo_text\": None, \"capitulo_text\": None, \"secao_text\": None, \"artigo_number\": None}\n",
    "            \n",
    "            # Search for hierarchy markers in the original text with hierarchy\n",
    "            for item in full_text_with_hierarchy:\n",
    "                if item[\"text\"] in chunk:\n",
    "                    # Update with the most specific hierarchy found\n",
    "                    if item[\"hierarchy\"][\"artigo_number\"]:\n",
    "                        best_hierarchy = item[\"hierarchy\"].copy()\n",
    "                        break\n",
    "                    elif item[\"hierarchy\"][\"secao_text\"] and not best_hierarchy[\"secao_text\"]:\n",
    "                        best_hierarchy = item[\"hierarchy\"].copy()\n",
    "                    elif item[\"hierarchy\"][\"capitulo_text\"] and not best_hierarchy[\"capitulo_text\"]:\n",
    "                        best_hierarchy = item[\"hierarchy\"].copy()\n",
    "                    elif item[\"hierarchy\"][\"titulo_text\"] and not best_hierarchy[\"titulo_text\"]:\n",
    "                        best_hierarchy = item[\"hierarchy\"].copy()\n",
    "            \n",
    "            # Update metadata with hierarchy\n",
    "            chunk_metadata.update(best_hierarchy)\n",
    "            \n",
    "            chunk_metadata.update({\n",
    "                \"chunk_index\": idx,\n",
    "                \"total_chunks\": len(text_chunks),\n",
    "                \"full_hierarchical_path\": build_full_hierarchical_path(chunk_metadata)\n",
    "            })\n",
    "\n",
    "            all_chunks.append({\n",
    "                \"page_content\": chunk,\n",
    "                \"metadata\": chunk_metadata\n",
    "            })\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar o PDF: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        if 'doc' in locals():\n",
    "            doc.close()\n",
    "            \n",
    "    print(f\"Total de chunks processados: {len(all_chunks)}\")\n",
    "    return all_chunks\n",
    "\n",
    "# Test the function\n",
    "if download_pdf_if_not_exists(PDF_URL, LOCAL_PDF_PATH):\n",
    "    print(\"\\n=== Testing Comprehensive Parsing ===\")\n",
    "    chunks = parse_aneel_pdf(LOCAL_PDF_PATH)\n",
    "    print(f\"Total chunks extracted: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5290276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "import chromadb\n",
    "\n",
    "from text_processor_2 import parse_aneel_pdf, download_pdf_if_not_exists, PDF_URL, LOCAL_PDF_PATH\n",
    "from vector_db import initialize_vector_db, query_vector_db, COLLECTION_NAME\n",
    "from chatbot_logic import generate_response_with_gemini\n",
    "\n",
    "# --- Configura√ß√£o ---\n",
    "CHROMA_PERSIST_DIR = r\"./chroma_db_data\"\n",
    "DB_READY_FLAG = \"db_initialized.flag\"  # Arquivo de flag para verificar se o banco de dados foi inicializado\n",
    "\n",
    "# --- Fun√ß√£o auxiliar para Checar/Construir o banco de dados ---\n",
    "def ensure_db_is_ready():\n",
    "    \"\"\"\n",
    "    Verifica se o banco de dados vetorial est√° pronto. Se n√£o estiver, inicializa-o.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(DB_READY_FLAG):\n",
    "        st.info(\"Base de dados vetorial n√£o encontrada. Inicializando...\")\n",
    "        st.info(\"Baixando e processando o PDF da Resolu√ß√£o Normativa 1000 da ANEEL...\")\n",
    "        with st.spinner(\"Isso pode levar alguns minutos... ‚è≥\"):\n",
    "            # Download PDF if needed\n",
    "            if download_pdf_if_not_exists(PDF_URL, LOCAL_PDF_PATH):\n",
    "                # Parse PDF and extract chunks with hierarchy\n",
    "                chunks_with_metadata = parse_aneel_pdf(LOCAL_PDF_PATH)\n",
    "                \n",
    "                # Extract just the text content for vector DB\n",
    "                text_chunks = [chunk[\"page_content\"] for chunk in chunks_with_metadata]\n",
    "                \n",
    "                # Extract metadata for vector DB\n",
    "                metadatas = [chunk[\"metadata\"] for chunk in chunks_with_metadata]\n",
    "                \n",
    "                # Initialize vector database with chunks and metadata\n",
    "                initialize_vector_db_with_metadata(text_chunks, metadatas, persist_directory=CHROMA_PERSIST_DIR)\n",
    "                \n",
    "                # Create flag file\n",
    "                with open(DB_READY_FLAG, 'w') as f:\n",
    "                    f.write(\"Database initialized with PDF content\")\n",
    "            else:\n",
    "                st.error(\"Erro ao baixar o PDF. Verifique sua conex√£o com a internet.\")\n",
    "                return\n",
    "                \n",
    "        st.success(\"Base de dados vetorial inicializada com sucesso! ‚úÖ\")\n",
    "    else:\n",
    "        # Load existing collection\n",
    "        try:\n",
    "            client = chromadb.PersistentClient(path=CHROMA_PERSIST_DIR)\n",
    "            collection = client.get_collection(name=COLLECTION_NAME)\n",
    "            import vector_db\n",
    "            vector_db.client = client  # Update global client\n",
    "            vector_db.collection = collection  # Update global collection\n",
    "            st.sidebar.success(f\"Base de dados vetorial '{COLLECTION_NAME}' carregada com sucesso! ‚úÖ\")\n",
    "        except Exception as e:\n",
    "            st.sidebar.error(f\"Erro ao carregar a base de dados vetorial: {e}. Tentando recriar...\")\n",
    "            if os.path.exists(DB_READY_FLAG):\n",
    "                os.remove(DB_READY_FLAG)  # Remove flag to force reinitialization\n",
    "            ensure_db_is_ready()\n",
    "\n",
    "def initialize_vector_db_with_metadata(documents: list[str], metadatas: list[dict], persist_directory: str = r\"./chroma_db_data\"):\n",
    "    \"\"\"\n",
    "    Initialize vector database with documents and their metadata.\n",
    "    \"\"\"\n",
    "    client = chromadb.PersistentClient(path=persist_directory)\n",
    "\n",
    "    try:\n",
    "        collection = client.get_collection(name=COLLECTION_NAME)\n",
    "        print(f\"Cole√ß√£o '{COLLECTION_NAME}' j√° existe. Removendo para recriar...\")\n",
    "        client.delete_collection(name=COLLECTION_NAME)\n",
    "    except:\n",
    "        pass  # Collection doesn't exist, which is fine\n",
    "\n",
    "    print(f\"Criando nova cole√ß√£o '{COLLECTION_NAME}'...\")\n",
    "    collection = client.create_collection(name=COLLECTION_NAME)\n",
    "\n",
    "    # Create document IDs\n",
    "    doc_ids = [f\"doc_{i}\" for i in range(len(documents))]\n",
    "    \n",
    "    # Add documents with metadata\n",
    "    collection.add(\n",
    "        documents=documents,\n",
    "        ids=doc_ids,\n",
    "        metadatas=metadatas\n",
    "    )\n",
    "    \n",
    "    # Update global variables\n",
    "    import vector_db\n",
    "    vector_db.client = client\n",
    "    vector_db.collection = collection\n",
    "    \n",
    "    print(f\"Banco de dados vetorial inicializado com {len(documents)} documentos com metadados.\")\n",
    "    return collection\n",
    "\n",
    "# --- Streamlit App ---\n",
    "st.set_page_config(page_title=\"ANEEL Chatbot\", page_icon=\":robot_face:\", layout=\"wide\")\n",
    "st.title(\"üí¨ Chatbot Inteligente de Leis da ANEEL (REN1000/2021)\")\n",
    "st.markdown(\"\"\"\n",
    "Bem-vindo(a)! Pergunte sobre a Resolu√ß√£o Normativa ANEEL n¬∫ 1000/2021.\n",
    "Este chatbot utiliza a Google Generative AI para responder √†s suas perguntas com base nos textos da lei.\n",
    "\"\"\")\n",
    "\n",
    "# --- Sidebar para Chave de API do Gemini e Status do Banco de Dados ---\n",
    "st.sidebar.header(\"Configura√ß√µes\")\n",
    "api_key_input = st.sidebar.text_input(\n",
    "    \"Sua Chave de API Gemini (GOOGLE_API_KEY):\",\n",
    "    type=\"password\",\n",
    "    help=\"Obtenha sua chave em https://aistudio.google.com/app/apikey\"\n",
    ")\n",
    "\n",
    "# Determina qual chave usar (entrada do usu√°rio tem prioridade)\n",
    "api_key = api_key_input or os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if api_key:\n",
    "    # Configura a chave no ambiente se foi fornecida via input\n",
    "    if api_key_input:\n",
    "        os.environ[\"GOOGLE_API_KEY\"] = api_key_input\n",
    "    \n",
    "    # Configura o cliente Gemini\n",
    "    try:\n",
    "        import google.generativeai as genai\n",
    "        genai.configure(api_key=api_key)\n",
    "        \n",
    "        if api_key_input:\n",
    "            st.sidebar.success(\"Chave de API configurada com sucesso! ‚úÖ\")\n",
    "        else:\n",
    "            st.sidebar.info(\"Chave de API j√° configurada no ambiente. ‚úÖ\")\n",
    "    except Exception as e:\n",
    "        st.sidebar.error(f\"Erro ao configurar a chave de API: {e}\")\n",
    "else:\n",
    "    st.sidebar.warning(\"Por favor, insira sua chave de API Gemini para continuar.\")\n",
    "    st.stop()\n",
    "\n",
    "# Verifica se o banco de dados vetorial est√° pronto antes de permitir consultas\n",
    "ensure_db_is_ready()\n",
    "\n",
    "# Inicializa o hist√≥rico de mensagens\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# Mostra o hist√≥rico de mensagens quando o app √© recarregado\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "\n",
    "# Recebe a pergunta do usu√°rio\n",
    "if prompt := st.chat_input(\"Qual a sua pergunta sobre a REN 1000/2021 da ANEEL?\"):\n",
    "    # Adiciona a pergunta ao hist√≥rico\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    # Exibe a pergunta na interface\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(prompt)\n",
    "    \n",
    "    # Mostra a resposta da IA em um container de mensagem\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        message_placeholder = st.empty()\n",
    "        message_placeholder.markdown(\"**Pensando...** üß†\")\n",
    "\n",
    "        # 1. Consulta o banco de dados vetorial\n",
    "        retrieved_chunks = query_vector_db(prompt, n_results=3)\n",
    "        \n",
    "        if not retrieved_chunks:\n",
    "            full_response = \"Desculpe, n√£o consegui encontrar informa√ß√µes relevantes nos documentos consultados para responder √† sua pergunta.\"\n",
    "        else:\n",
    "            # 2. Gera a resposta usando o modelo Gemini\n",
    "            full_response = generate_response_with_gemini(prompt, retrieved_chunks)\n",
    "\n",
    "        # Atualiza a mensagem com a resposta final\n",
    "        message_placeholder.markdown(full_response)\n",
    "        \n",
    "        # Show sources with hierarchical information\n",
    "        with st.expander(\"Ver fontes e contexto\"):\n",
    "            # Get the last query results with metadata\n",
    "            if hasattr(st.session_state, 'last_query_results'):\n",
    "                results = st.session_state.last_query_results\n",
    "                for i, (doc, metadata) in enumerate(zip(results.get('documents', [[]])[0], results.get('metadatas', [[]])[0])):\n",
    "                    st.caption(f\"**Fonte {i+1}:**\")\n",
    "                    if metadata.get('full_hierarchical_path'):\n",
    "                        st.caption(f\"üìç **Localiza√ß√£o:** {metadata['full_hierarchical_path']}\")\n",
    "                    st.caption(f\"üìÑ **Conte√∫do:** {doc[:200]}...\")\n",
    "                    st.divider()\n",
    "            else:\n",
    "                for i, doc in enumerate(retrieved_chunks):\n",
    "                    st.caption(f\"**Fonte {i+1}:** {doc[:200]}...\")\n",
    "    \n",
    "    # Adiciona a resposta ao hist√≥rico\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5408f216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cleaned Text (first 500 characters) ---\n",
      "AG√äNCIA NACIONAL DE ENERGIA EL√âTRICA ‚Äì ANEEL\n",
      "RESOLU√á√ÉO NORMATIVA ANEEL N¬∫ 1.000, DE 7 DE DEZEMBRO DE 2021(*)\n",
      "Estabelece as Regras de Presta√ß√£o do Servi√ßo P√∫blico de Distribui√ß√£o de Energia El√©trica; revoga as Resolu√ß√µes Normativas ANEEL n¬∫\n",
      "414\n",
      ", de 9 de setembro de 2010; n¬∫\n",
      "470\n",
      ", de 13 de dezembro de 2011; n¬∫\n",
      "901\n",
      ", de 8 de dezembro de 2020 e d√° outras provid√™ncias.\n",
      "Decis√£o Judicial\n",
      "Despacho 2.006/2024: Decis√£o Judicial - suspensos os efeitos referentes ao prazo de 60 (sessenta) ciclos estabeleci\n",
      "\n",
      "Cleaned text saved to '../data/cleaned_text.txt'.\n"
     ]
    }
   ],
   "source": [
    "# data_preprocess.py\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "\n",
    "ANEEL_RES_PATH = r\"../data/ren20211000.html\"\n",
    "ANEEL_RES_PATH_2 = r\"../data/ren20211000_2.html\"\n",
    "def fetch_html_content(url: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Faz uma requisi√ß√£o HTTP para obter o conte√∫do HTML de uma URL.\n",
    "    :param url: URL do qual o conte√∫do HTML ser√° obtido.\n",
    "    :return: Conte√∫do HTML como string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Verifica se a requisi√ß√£o foi bem-sucedida\n",
    "        \n",
    "        # Get encoding from response headers or detect it\n",
    "        if response.encoding is None or response.encoding == 'ISO-8859-1':\n",
    "            # Try to detect encoding from content\n",
    "            response.encoding = response.apparent_encoding\n",
    "        \n",
    "        # If still no proper encoding, default to utf-8\n",
    "        if response.encoding is None:\n",
    "            response.encoding = 'utf-8'\n",
    "            \n",
    "        return response.text\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Erro ao obter conte√∫do HTML de {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def clean_html(html_path: str) -> str:\n",
    "    \"\"\"\n",
    "    L√™ um arquivo HTML, remove elementos com estilo `text-decoration: line-through` e extrai o texto limpo.\n",
    "    : param html_path: Caminho para o arquivo HTML a ser processado.\n",
    "    : return: Texto limpo extra√≠do do HTML.\n",
    "    \"\"\"\n",
    "    with open(html_path, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'lxml')\n",
    "    \n",
    "    for strike in soup.find_all(style=re.compile('line-through')):\n",
    "        strike.decompose()\n",
    "    \n",
    "    # Extract clean text\n",
    "    return soup.get_text(separator='\\n', strip=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cleaned_text = clean_html(ANEEL_RES_PATH)\n",
    "    print(\"\\n--- Cleaned Text (first 500 characters) ---\")\n",
    "    print(cleaned_text[:500])\n",
    "\n",
    "    with open(r\"../data/cleaned_text.txt\", \"w\", encoding='utf-8') as output_file:\n",
    "        output_file.write(cleaned_text)\n",
    "    print(\"\\nCleaned text saved to '../data/cleaned_text.txt'.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cdc3039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Text Chunks (first 3 chunks) ---\n",
      "Chunk 1:\n",
      "AG√äNCIA NACIONAL DE ENERGIA EL√âTRICA ‚Äì ANEEL\n",
      "RESOLU√á√ÉO NORMATIVA ANEEL N¬∫ 1.000, DE 7 DE DEZEMBRO DE 2021(*)\n",
      "Estabelece as Regras de Presta√ß√£o do Servi√ßo P√∫blico de Distribui√ß√£o de Energia El√©trica; revoga as Resolu√ß√µes Normativas ANEEL n¬∫\n",
      "414\n",
      ", de 9 de setembro de 2010; n¬∫\n",
      "470\n",
      ", de 13 de dezembro de 2011; n¬∫\n",
      "901\n",
      ", de 8 de dezembro de 2020 e d√° outras provid√™ncias.\n",
      "Decis√£o Judicial\n",
      "Despacho 2.006/2024: Decis√£o Judicial - suspensos os efeitos referentes ao prazo de 60 (sessenta) ciclos estabelecidos no inciso II do art. 323\n",
      ".\n",
      "Voto\n",
      "Texto Compilado\n",
      "O DIRETOR-GERAL DA AG√äNCIA NACIONAL DE ENERGIA EL√âTRICA ‚Äì ANEEL, no uso de suas atribui√ß√µes regimentais, de acordo com a delibera√ß√£o da Diretoria, tendo em vista o disposto na Lei n¬∫ 9.427, de 26 de dezembro de 1996, no Decreto n¬∫ 2.335, de 6 de outubro de 1997 e o que consta do Processo n¬∫ 48500.005218/2020-06, resolve:\n",
      "T√çTULO I\n",
      "PARTE GERAL\n",
      "CAP√çTULO I\n",
      "DAS DISPOSI√á√ïES GERAIS\n",
      "Se√ß√£o I\n",
      "Do Objeto e √Çmbito de Aplica√ß√£o\n",
      "\n",
      "Chunk 2:\n",
      "T√çTULO I\n",
      "PARTE GERAL\n",
      "CAP√çTULO I\n",
      "DAS DISPOSI√á√ïES GERAIS\n",
      "Se√ß√£o I\n",
      "Do Objeto e √Çmbito de Aplica√ß√£o\n",
      "Art. 1¬∫ Esta Resolu√ß√£o Normativa estabelece as Regras de Presta√ß√£o do Servi√ßo P√∫blico de Distribui√ß√£o de Energia El√©trica, nas quais est√£o dispostos os direitos e deveres do consumidor e demais usu√°rios do servi√ßo.\n",
      "¬ß 1¬∫\n",
      "O disposto nesta Resolu√ß√£o aplica-se √† concession√°ria e permission√°ria de servi√ßo p√∫blico de distribui√ß√£o de energia el√©trica e ao usu√°rio do servi√ßo, pessoa f√≠sica ou jur√≠dica que se beneficia ou utiliza, efetiva ou potencialmente, do servi√ßo p√∫blico, a exemplo de:\n",
      "I - consumidor;\n",
      "II - central geradora;\n",
      "III - distribuidora;\n",
      "IV - agente exportador; e\n",
      "V - agente importador.\n",
      "¬ß 2¬∫\n",
      "A aplica√ß√£o desta Resolu√ß√£o √© complementada pelos Procedimentos de Distribui√ß√£o de Energia El√©trica no Sistema El√©trico Nacional ‚Äì PRODIST e pelos Procedimentos de Regula√ß√£o Tarif√°ria - PRORET.\n",
      "¬ß 3¬∫\n",
      "\n",
      "Chunk 3:\n",
      "A aplica√ß√£o desta Resolu√ß√£o √© complementada pelos Procedimentos de Distribui√ß√£o de Energia El√©trica no Sistema El√©trico Nacional ‚Äì PRODIST e pelos Procedimentos de Regula√ß√£o Tarif√°ria - PRORET.\n",
      "¬ß 3¬∫\n",
      "A aplica√ß√£o desta Resolu√ß√£o n√£o afasta a necessidade de cumprimento do disposto na regula√ß√£o da ANEEL e na legisla√ß√£o, em especial:\n",
      "I - na Lei n¬∫ 8.078, de 11 de setembro de 1990, que instituiu o C√≥digo de Defesa do Consumidor e estabelece normas de prote√ß√£o e defesa do consumidor, de ordem p√∫blica e interesse social; e\n",
      "II - na Lei n¬∫ 13.460, de 26 de junho de 2017, que disp√µe sobre a participa√ß√£o, prote√ß√£o e defesa dos direitos do usu√°rio dos servi√ßos p√∫blicos.\n",
      "¬ß 4¬∫ Aplica-se o disposto nesta Resolu√ß√£o, de forma subsidi√°ria e complementar, ao consumidor e demais usu√°rios que acessam o sistema de distribui√ß√£o por meio de conex√£o √†s Demais Instala√ß√µes de Transmiss√£o ‚Äì DIT, ou que possuam contratos celebrados com a distribuidora.\n",
      "Se√ß√£o II\n",
      "Das Defini√ß√µes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# text_processor.py\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_text(text: str, chunk_size: int=1000, chunk_overlap: int=200) -> list[str]:\n",
    "    \"\"\"\n",
    "    Divide o texto em peda√ßos menores com base no tamanho e na sobreposi√ß√£o especificados.\n",
    "    : param text: String de texto a ser dividido.\n",
    "    : param chunk_size: Tamanho m√°ximo de cada peda√ßo de texto.\n",
    "    : param chunk_overlap: N√∫mero de caracteres que se sobrep√µem entre peda√ßos consecutivos.\n",
    "    : return: Lista de peda√ßos de texto divididos.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        add_start_index=True\n",
    "    )\n",
    "    documents = text_splitter.create_documents([text])\n",
    "    return [doc.page_content for doc in documents]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with open(r\"../data/cleaned_text.txt\", \"r\", encoding='utf-8') as file:\n",
    "        cleaned_text = file.read()\n",
    "\n",
    "    chunks = split_text(cleaned_text, chunk_size=1000, chunk_overlap=200)\n",
    "    print(\"\\n--- Text Chunks (first 3 chunks) ---\")\n",
    "    for i, chunk in enumerate(chunks[:3]):\n",
    "        print(f\"Chunk {i+1}:\\n{chunk}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27a739a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cole√ß√£o 'aneel_collection' carregada com sucesso.\n",
      "\n",
      "--- Vector Database Initialized ---\n",
      "\n",
      "Query: Quais s√£o as principais mudan√ßas na regulamenta√ß√£o de energia?\n",
      "\n",
      "Retrieved Documents:\n",
      "- Se√ß√£o III\n",
      "Do Contrato de Compra de Energia Regulada ‚Äì CCER\n",
      "Art. 162. O CCER deve conter as cl√°usulas gerais do art. 145 e, caso aplic√°veis, as do art. 132, al√©m de outras consideradas essenciais, observando as demais disposi√ß√µes deste Cap√≠tulo.\n",
      "Art. 163. O montante de energia el√©trica contratado por...\n",
      "- Art. 29. O consumidor e demais usu√°rios devem observar em suas instala√ß√µes as normas e padr√µes da distribuidora, as normas da Associa√ß√£o Brasileira de Normas T√©cnicas - ABNT e as normas dos √≥rg√£os oficiais competentes, naquilo que for aplic√°vel e n√£o contrariar √† regula√ß√£o da ANEEL.\n",
      "Art. 30. O consu...\n"
     ]
    }
   ],
   "source": [
    "# vector_db.py\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "client  = None\n",
    "collection = None\n",
    "COLLECTION_NAME = \"aneel_collection\"\n",
    "\n",
    "def initialize_vector_db(documents: list[str], persist_directory: str=r\"../chroma_db_data\"):\n",
    "    \"\"\"\n",
    "    Inicializa o banco de dados vetorial ChromaDB com os documentos fornecidos.\n",
    "    O embedding de documentos √© feito usando o modelo 'all-MiniLM-L6-v2'.\n",
    "    : param documents: Lista de documentos a serem armazenados no banco de dados.\n",
    "    : param persist_directory: Diret√≥rio onde o banco de dados ser√° persistido.\n",
    "    : return: Inst√¢ncia do cliente ChromaDB e cole√ß√£o criada.\n",
    "    \"\"\"\n",
    "    global client, collection\n",
    "    \n",
    "    client = chromadb.PersistentClient(path=persist_directory)\n",
    "\n",
    "    try:\n",
    "        collection = client.get_collection(name=COLLECTION_NAME)\n",
    "        print(f\"Cole√ß√£o '{COLLECTION_NAME}' carregada com sucesso.\")\n",
    "    except:\n",
    "        print(f\"Cole√ß√£o '{COLLECTION_NAME}' n√£o encontrada. Criando nova cole√ß√£o.\")\n",
    "        collection = client.create_collection(name=COLLECTION_NAME)\n",
    "        print(f\"Cole√ß√£o '{COLLECTION_NAME}' criada com sucesso.\")\n",
    "\n",
    "        doc_ids = [f\"doc_{i}\" for i in range(len(documents))]\n",
    "        collection.add(\n",
    "            documents=documents,\n",
    "            ids=doc_ids,\n",
    "            metadatas=[{\"source\": f\"doc_{i}\"} for i in range(len(documents))],\n",
    "        )\n",
    "        print(f\"Banco de dados vetorial inicializado com {len(documents)} documentos.\")\n",
    "    \n",
    "    return collection\n",
    "\n",
    "def query_vector_db(query_text: str, n_results: int=5) -> list[str]:\n",
    "    \"\"\"\n",
    "    Consulta o banco de dados vetorial ChromaDB com uma string de consulta.\n",
    "    : param query_text: Texto da consulta para buscar documentos relevantes.\n",
    "    : param n_results: N√∫mero de resultados a serem retornados.\n",
    "    : return: Lista de IDs dos documentos mais relevantes encontrados.\n",
    "    \"\"\"\n",
    "    global collection\n",
    "    if not collection:\n",
    "        print(\"Erro: Cole√ß√£o n√£o inicializada. Por favor, chame initialize_vector_db primeiro.\")\n",
    "        try:\n",
    "            global client\n",
    "            client = chromadb.PersistentClient(path=r\"../chroma_db_data\")\n",
    "            collection = client.get_collection(name=COLLECTION_NAME)\n",
    "            print(f\"Cole√ß√£o '{COLLECTION_NAME}' carregada com sucesso.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar a cole√ß√£o: {e}\")\n",
    "            return []\n",
    "    \n",
    "    if not query_text:\n",
    "        return []\n",
    "    \n",
    "    results = collection.query(\n",
    "        query_texts=[query_text],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    return results['documents'][0]  if results and results['documents'] else []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with open(r\"../data/cleaned_text.txt\", \"r\", encoding='utf-8') as file:\n",
    "        cleaned_text = file.read()\n",
    "    \n",
    "    chunks = split_text(cleaned_text)\n",
    "    initialize_vector_db(chunks)\n",
    "    print(\"\\n--- Vector Database Initialized ---\")\n",
    "\n",
    "    if collection:\n",
    "        query = \"Quais s√£o as principais mudan√ßas na regulamenta√ß√£o de energia?\"\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        retrieved_docs = query_vector_db(query, n_results=2)\n",
    "        if retrieved_docs:\n",
    "            print(\"\\nRetrieved Documents:\")\n",
    "            for doc in retrieved_docs:\n",
    "                print(f\"- {doc[:300]}...\")\n",
    "        else:\n",
    "            print(\"Nenhum documento encontrado para a consulta.\")\n",
    "    else:\n",
    "        print(\"Falha ao inicializar a cole√ß√£o. Verifique os logs para mais detalhes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a700c6be",
   "metadata": {},
   "source": [
    "General text: 500-1000 characters\n",
    "\n",
    "Technical docs: 300-800 characters\n",
    "\n",
    "Code: 200-500 characters (split at logical boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16dac854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved Documents:\n",
      "- Se√ß√£o XI\n",
      "Do Per√≠odo de Testes e Ajustes\n",
      "Art. 311. A distribuidora deve aplicar o per√≠odo de testes para unidade consumidora para permitir a adequa√ß√£o da demanda contratada de consumo e a escolha da modalidade tarif√°ria, nas seguintes situa√ß√µes: (\n",
      "Reda√ß√£o dada pela REN ANEEL 1.059, de 07.02.2023\n",
      ")\n",
      "I - in√≠cio do fornecimento de energia el√©trica;\n",
      "II - mudan√ßa para faturamento aplic√°vel √† unidade consumidora do grupo\n",
      "A, cuja op√ß√£o anterior tenha sido por faturamento do grupo B;\n",
      "III - enquadramento na modalidade tarif√°ria hor√°ria azul; e\n",
      "IV - acr√©scimo de demanda, quando maior que 5% da contratada.\n",
      "Par√°grafo √∫nico. Quando do enquadramento na modalidade tarif√°ria hor√°ria azul, o per√≠odo de testes abranger√° exclusivamente o montante contratado para o posto tarif√°rio ponta.\n",
      "Art. 312. O per√≠odo de testes deve ter dura√ß√£o de 3 ciclos consecutivos e completos de faturamento.\n",
      "Par√°grafo √∫nico.\n",
      "A distribuidora pode prorrogar o per√≠odo de testes, mediante solicita√ß√£o fundamentada do consumidor....\n",
      "- Art. 315. A distribuidora deve fornecer ao consumidor, sempre que solicitada, as informa√ß√µes necess√°rias √† simula√ß√£o do faturamento relacionadas ao per√≠odo de testes.\n",
      "Art. 316. A distribuidora deve conceder para unidade consumidora do grupo A um per√≠odo de ajustes no in√≠cio do fornecimento de energia el√©trica, para adequa√ß√£o do fator de pot√™ncia, com dura√ß√£o de 3 ciclos consecutivos e completos de faturamento.\n",
      "¬ß 1¬∫\n",
      "A distribuidora pode prorrogar o per√≠odo de ajustes mediante solicita√ß√£o fundamentada do consumidor.\n",
      "¬ß 2¬∫\n",
      "A distribuidora deve calcular e informar ao consumidor os valores de energia el√©trica e demanda de pot√™ncia reativas excedentes durante o per√≠odo de ajustes, sem efetuar a cobran√ßa.\n",
      "Art. 317. A distribuidora pode iniciar o faturamento e, sendo aplic√°veis, os per√≠odos de testes e de ajustes,\n",
      "nas datas previstas no CUSD, devendo observar:\n",
      "I - as condi√ß√µes de suspens√£o de obra, de que trata o art. 89; e\n",
      "II - as condi√ß√µes de prorroga√ß√£o do CUSD, de que trata o art. 157....\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs = query_vector_db(\"Qual √© o periodo de testes para unidade consumidara?\", n_results=2)\n",
    "if retrieved_docs:\n",
    "    print(\"\\nRetrieved Documents:\")\n",
    "    for doc in retrieved_docs:\n",
    "        print(f\"- {doc}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f3185e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved Documents for Test Query:\n",
      "- ¬ß 3¬∫ A distribuidora deve disponibilizar a fatura de energia el√©trica completa no espa√ßo reservado de atendimento pela internet, independentemente da op√ß√£o pelo resumo da fatura.\n",
      "Art. 329. A distribuidora deve prestar ao consumidor e demais usu√°rios esclarecimentos sobre os tributos, subven√ß√µes e in...\n",
      "- VII - formalidades e exig√™ncias que sejam incompat√≠veis com a boa-f√©, excessivamente onerosas ou cujo custo econ√¥mico ou social seja superior ao risco envolvido.\n",
      "Par√°grafo √∫nico. No caso de n√∫cleo urbano informal consolidado, nos termos da Lei n¬∫ 13.465, de 11 de julho de 2017, a comprova√ß√£o de poss...\n",
      "\n",
      "--- Response from Gemini ---\n",
      "Todas as informa√ß√µes da primeira via, com destaque √† express√£o \"segunda via\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# chatbot_logic.py\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "try:\n",
    "    if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "        raise ValueError(\"A vari√°vel de ambiente GOOGLE_API_KEY n√£o est√° definida.\")\n",
    "    genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "except ValueError as e:\n",
    "    print(f\"Erro de configura√ß√£o: {e}. Garanta que a vari√°vel de ambiente GOOGLE_API_KEY esteja definida.\")\n",
    "\n",
    "def generate_response_with_gemini(query: str, context_chuncks: list[str]) -> str:\n",
    "    \"\"\"\n",
    "    Gera uma resposta usando o modelo Gemini da Google Generative AI, incorporando o contexto dos documentos recuperados.\n",
    "    : param query: Texto da consulta do usu√°rio.\n",
    "    : param context_chuncks: Lista de peda√ßos de texto que fornecem contexto adicional para a resposta.\n",
    "    : return: Resposta gerada pelo modelo Gemini.\n",
    "    \"\"\"\n",
    "    if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "        raise ValueError(\"A vari√°vel de ambiente GOOGLE_API_KEY n√£o est√° definida.\")\n",
    "    \n",
    "    # Prepara o contexto para a consulta\n",
    "    context_str = \"\\n\\n---\\n\\n\".join(context_chuncks)\n",
    "    prompt = f\"\"\"\n",
    "    Voc√™ √© um assistente de IA especializado em leis e regulamentos brasileiros da ANEEL.\n",
    "    Sua tarefa √© responder √† pergunta do usu√°rio com base estritamente nos trechos de lei fornecidos abaixo.\n",
    "    N√£o utilize conhecimento externo. Se a resposta n√£o puder ser encontrada nos trechos fornecidos,\n",
    "    declare explicitamente que a informa√ß√£o n√£o est√° dispon√≠vel nos documentos consultados.\n",
    "    Seja conciso e direto ao ponto. Responda em portugu√™s brasileiro.\n",
    "    \n",
    "    **Contexto (Trechos da Lei):**\n",
    "    {context_str}\n",
    "    \n",
    "    **Pergunta do Usu√°rio:**\n",
    "    {query}\n",
    "\n",
    "**Sua Resposta:**\n",
    "\"\"\"\n",
    "    try:\n",
    "        model = genai.GenerativeModel(model_name=\"gemini-1.5-flash-8b\")\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao gerar resposta com Gemini: {e}\")\n",
    "        return \"Desculpe, ocorreu um erro ao processar sua consulta. Tente novamente mais tarde.\"\n",
    "\n",
    "test_user_query = \"O que deve constar na segunda via de fatura?\"\n",
    "retrieved_docs = query_vector_db(test_user_query, n_results=2)\n",
    "if retrieved_docs:\n",
    "    print(\"\\nRetrieved Documents for Test Query:\")\n",
    "    for doc in retrieved_docs:\n",
    "        print(f\"- {doc[:300]}...\")\n",
    "\n",
    "    response = generate_response_with_gemini(test_user_query, retrieved_docs)\n",
    "    print(\"\\n--- Response from Gemini ---\")\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
