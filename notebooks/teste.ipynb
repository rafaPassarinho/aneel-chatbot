{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "37917bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo ../data/atren20211000.pdf já existe. Usando arquivo local.\n",
      "\n",
      "=== Testing Comprehensive Parsing ===\n",
      "Processando PDF: ../data/atren20211000.pdf com 314 páginas.\n",
      "Total de chunks processados: 549\n",
      "Total chunks extracted: 549\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import re\n",
    "import requests\n",
    "import os\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "PDF_URL = \"https://www2.aneel.gov.br/cedoc/atren20211000.pdf\"\n",
    "LOCAL_PDF_PATH = r\"../data/atren20211000.pdf\"\n",
    "\n",
    "# Document metadata\n",
    "DOC_INFO_DEFAULTS = {\n",
    "    \"source_document_url\": PDF_URL,\n",
    "    \"source_document_name\": LOCAL_PDF_PATH,\n",
    "    \"document_type\": \"Resolução Normativa\",\n",
    "    \"issuer\": \"ANEEL\"\n",
    "}\n",
    "\n",
    "# Optimized patterns based on actual PDF structure\n",
    "PATTERNS = {\n",
    "    \"titulo\": re.compile(r\"^\\s*T[ÍI]TULO\\s+([IVXLCDM]+)\\s*$\", re.IGNORECASE),\n",
    "    \"capitulo\": re.compile(r\"^\\s*CAP[ÍI]TULO\\s+([IVXLCDM]+)\\s*$\", re.IGNORECASE),\n",
    "    \"secao\": re.compile(r\"^\\s*(?:SUB)?[Ss]e[çc][ãa]o\\s+([IVXLCDM]+)\\s*$\", re.IGNORECASE),\n",
    "    \"artigo_start\": re.compile(r\"^\\s*Art\\.\\s*(\\d+(?:[A-Za-z])?º?)\\s+(.*)\", re.IGNORECASE),\n",
    "    \"paragrafo_start\": re.compile(r\"^\\s*§\\s*(\\d+º?|único)\\s+(.+)\", re.IGNORECASE),\n",
    "    \"inciso_start\": re.compile(r\"^\\s*([IVXLCDM]+(?:-[A-Z])?)\\s*-\\s*(.+)\"),\n",
    "    \"alinea_start\": re.compile(r\"^\\s*([a-z])\\)\\s*(.+)\")\n",
    "}\n",
    "\n",
    "def clean_text_line(text: str) -> str:\n",
    "    \"\"\"Clean text by replacing special characters and normalizing whitespace.\"\"\"\n",
    "    replacements = {\n",
    "        '\\xa0': ' ',  # Non-breaking space\n",
    "        '\\xad': '',   # Soft hyphen\n",
    "        '\\u2013': '-', # En dash\n",
    "        '\\u2014': '-'  # Em dash\n",
    "    }\n",
    "    for k, v in replacements.items():\n",
    "        text = text.replace(k, v)\n",
    "    return text.strip()\n",
    "\n",
    "def download_pdf_if_not_exists(url: str, local_path: str) -> bool:\n",
    "    \"\"\"Download PDF if it doesn't exist locally.\"\"\"\n",
    "    if os.path.exists(local_path):\n",
    "        print(f\"Arquivo {local_path} já existe. Usando arquivo local.\")\n",
    "        return True\n",
    "    \n",
    "    print(f\"Baixando PDF de {url} para {local_path}...\")\n",
    "    try:\n",
    "        response = requests.get(url, stream=True, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        with open(local_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        print(f\"PDF baixado com sucesso: {local_path}\")\n",
    "        return True\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Erro ao baixar o PDF: {e}\")\n",
    "        return False\n",
    "\n",
    "def build_full_hierarchical_path(metadata_dict: dict) -> str:\n",
    "    \"\"\"Build complete hierarchical path from metadata dictionary.\"\"\"\n",
    "    components = [\n",
    "        metadata_dict.get(\"titulo_text\"),\n",
    "        metadata_dict.get(\"capitulo_text\"),\n",
    "        metadata_dict.get(\"secao_text\"),\n",
    "        metadata_dict.get(\"artigo_number\"),\n",
    "    ]\n",
    "    return \" > \".join(filter(None, components))\n",
    "\n",
    "def parse_aneel_pdf(\n",
    "        pdf_path: str,\n",
    "        max_chunk_size: int = 1500,\n",
    "        chunk_overlap: int = 200\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Comprehensive parsing that captures ALL content and properly tracks hierarchy.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(pdf_path):\n",
    "        raise FileNotFoundError(f\"Arquivo PDF não encontrado: {pdf_path}\")\n",
    "    \n",
    "    all_chunks = []\n",
    "    current_hierarchy = {\n",
    "        \"titulo_text\": None,\n",
    "        \"capitulo_text\": None,\n",
    "        \"secao_text\": None,\n",
    "        \"artigo_number\": None\n",
    "    }\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=max_chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \"; \", \" \", \"\"],\n",
    "        strip_whitespace=True\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        print(f\"Processando PDF: {pdf_path} com {len(doc)} páginas.\")\n",
    "\n",
    "        # First pass: track hierarchy as we go through the document\n",
    "        full_text_with_hierarchy = []\n",
    "        \n",
    "        for page_num, page in enumerate(doc, 1):\n",
    "            page_text = page.get_text()\n",
    "            if not page_text.strip():\n",
    "                continue\n",
    "                \n",
    "            lines = page_text.split('\\n')\n",
    "            for line in lines:\n",
    "                line_clean = clean_text_line(line).strip()\n",
    "                if not line_clean:\n",
    "                    continue\n",
    "                \n",
    "                # Check for hierarchy updates\n",
    "                titulo_match = PATTERNS[\"titulo\"].match(line_clean)\n",
    "                capitulo_match = PATTERNS[\"capitulo\"].match(line_clean)\n",
    "                secao_match = PATTERNS[\"secao\"].match(line_clean)\n",
    "                artigo_match = PATTERNS[\"artigo_start\"].match(line_clean)\n",
    "                \n",
    "                if titulo_match:\n",
    "                    current_hierarchy.update({\n",
    "                        \"titulo_text\": f\"TÍTULO {titulo_match.group(1)}\",\n",
    "                        \"capitulo_text\": None,\n",
    "                        \"secao_text\": None,\n",
    "                        \"artigo_number\": None\n",
    "                    })\n",
    "                elif capitulo_match:\n",
    "                    current_hierarchy.update({\n",
    "                        \"capitulo_text\": f\"CAPÍTULO {capitulo_match.group(1)}\",\n",
    "                        \"secao_text\": None,\n",
    "                        \"artigo_number\": None\n",
    "                    })\n",
    "                elif secao_match:\n",
    "                    current_hierarchy.update({\n",
    "                        \"secao_text\": f\"Seção {secao_match.group(1)}\",\n",
    "                        \"artigo_number\": None\n",
    "                    })\n",
    "                elif artigo_match:\n",
    "                    current_hierarchy[\"artigo_number\"] = f\"Art. {artigo_match.group(1)}\"\n",
    "                \n",
    "                # Store text with current hierarchy context\n",
    "                full_text_with_hierarchy.append({\n",
    "                    \"text\": line_clean,\n",
    "                    \"page\": page_num,\n",
    "                    \"hierarchy\": current_hierarchy.copy()  # Important: copy the dict\n",
    "                })\n",
    "        \n",
    "        # Second pass: create chunks with proper hierarchy metadata\n",
    "        all_text = \"\\n\".join([item[\"text\"] for item in full_text_with_hierarchy])\n",
    "        text_chunks = text_splitter.split_text(all_text)\n",
    "        \n",
    "        for idx, chunk in enumerate(text_chunks):\n",
    "            # Find the most relevant hierarchy for this chunk\n",
    "            chunk_metadata = DOC_INFO_DEFAULTS.copy()\n",
    "            \n",
    "            # Look for hierarchy elements in the chunk text\n",
    "            best_hierarchy = {\"titulo_text\": None, \"capitulo_text\": None, \"secao_text\": None, \"artigo_number\": None}\n",
    "            \n",
    "            # Search for hierarchy markers in the original text with hierarchy\n",
    "            for item in full_text_with_hierarchy:\n",
    "                if item[\"text\"] in chunk:\n",
    "                    # Update with the most specific hierarchy found\n",
    "                    if item[\"hierarchy\"][\"artigo_number\"]:\n",
    "                        best_hierarchy = item[\"hierarchy\"].copy()\n",
    "                        break\n",
    "                    elif item[\"hierarchy\"][\"secao_text\"] and not best_hierarchy[\"secao_text\"]:\n",
    "                        best_hierarchy = item[\"hierarchy\"].copy()\n",
    "                    elif item[\"hierarchy\"][\"capitulo_text\"] and not best_hierarchy[\"capitulo_text\"]:\n",
    "                        best_hierarchy = item[\"hierarchy\"].copy()\n",
    "                    elif item[\"hierarchy\"][\"titulo_text\"] and not best_hierarchy[\"titulo_text\"]:\n",
    "                        best_hierarchy = item[\"hierarchy\"].copy()\n",
    "            \n",
    "            # Update metadata with hierarchy\n",
    "            chunk_metadata.update(best_hierarchy)\n",
    "            \n",
    "            chunk_metadata.update({\n",
    "                \"chunk_index\": idx,\n",
    "                \"total_chunks\": len(text_chunks),\n",
    "                \"full_hierarchical_path\": build_full_hierarchical_path(chunk_metadata)\n",
    "            })\n",
    "\n",
    "            all_chunks.append({\n",
    "                \"page_content\": chunk,\n",
    "                \"metadata\": chunk_metadata\n",
    "            })\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar o PDF: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        if 'doc' in locals():\n",
    "            doc.close()\n",
    "            \n",
    "    print(f\"Total de chunks processados: {len(all_chunks)}\")\n",
    "    return all_chunks\n",
    "\n",
    "# Test the function\n",
    "if download_pdf_if_not_exists(PDF_URL, LOCAL_PDF_PATH):\n",
    "    print(\"\\n=== Testing Comprehensive Parsing ===\")\n",
    "    chunks = parse_aneel_pdf(LOCAL_PDF_PATH)\n",
    "    print(f\"Total chunks extracted: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5290276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "import chromadb\n",
    "\n",
    "from text_processor_2 import parse_aneel_pdf, download_pdf_if_not_exists, PDF_URL, LOCAL_PDF_PATH\n",
    "from vector_db import initialize_vector_db, query_vector_db, COLLECTION_NAME\n",
    "from chatbot_logic import generate_response_with_gemini\n",
    "\n",
    "# --- Configuração ---\n",
    "CHROMA_PERSIST_DIR = r\"./chroma_db_data\"\n",
    "DB_READY_FLAG = \"db_initialized.flag\"  # Arquivo de flag para verificar se o banco de dados foi inicializado\n",
    "\n",
    "# --- Função auxiliar para Checar/Construir o banco de dados ---\n",
    "def ensure_db_is_ready():\n",
    "    \"\"\"\n",
    "    Verifica se o banco de dados vetorial está pronto. Se não estiver, inicializa-o.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(DB_READY_FLAG):\n",
    "        st.info(\"Base de dados vetorial não encontrada. Inicializando...\")\n",
    "        st.info(\"Baixando e processando o PDF da Resolução Normativa 1000 da ANEEL...\")\n",
    "        with st.spinner(\"Isso pode levar alguns minutos... ⏳\"):\n",
    "            # Download PDF if needed\n",
    "            if download_pdf_if_not_exists(PDF_URL, LOCAL_PDF_PATH):\n",
    "                # Parse PDF and extract chunks with hierarchy\n",
    "                chunks_with_metadata = parse_aneel_pdf(LOCAL_PDF_PATH)\n",
    "                \n",
    "                # Extract just the text content for vector DB\n",
    "                text_chunks = [chunk[\"page_content\"] for chunk in chunks_with_metadata]\n",
    "                \n",
    "                # Extract metadata for vector DB\n",
    "                metadatas = [chunk[\"metadata\"] for chunk in chunks_with_metadata]\n",
    "                \n",
    "                # Initialize vector database with chunks and metadata\n",
    "                initialize_vector_db_with_metadata(text_chunks, metadatas, persist_directory=CHROMA_PERSIST_DIR)\n",
    "                \n",
    "                # Create flag file\n",
    "                with open(DB_READY_FLAG, 'w') as f:\n",
    "                    f.write(\"Database initialized with PDF content\")\n",
    "            else:\n",
    "                st.error(\"Erro ao baixar o PDF. Verifique sua conexão com a internet.\")\n",
    "                return\n",
    "                \n",
    "        st.success(\"Base de dados vetorial inicializada com sucesso! ✅\")\n",
    "    else:\n",
    "        # Load existing collection\n",
    "        try:\n",
    "            client = chromadb.PersistentClient(path=CHROMA_PERSIST_DIR)\n",
    "            collection = client.get_collection(name=COLLECTION_NAME)\n",
    "            import vector_db\n",
    "            vector_db.client = client  # Update global client\n",
    "            vector_db.collection = collection  # Update global collection\n",
    "            st.sidebar.success(f\"Base de dados vetorial '{COLLECTION_NAME}' carregada com sucesso! ✅\")\n",
    "        except Exception as e:\n",
    "            st.sidebar.error(f\"Erro ao carregar a base de dados vetorial: {e}. Tentando recriar...\")\n",
    "            if os.path.exists(DB_READY_FLAG):\n",
    "                os.remove(DB_READY_FLAG)  # Remove flag to force reinitialization\n",
    "            ensure_db_is_ready()\n",
    "\n",
    "def initialize_vector_db_with_metadata(documents: list[str], metadatas: list[dict], persist_directory: str = r\"./chroma_db_data\"):\n",
    "    \"\"\"\n",
    "    Initialize vector database with documents and their metadata.\n",
    "    \"\"\"\n",
    "    client = chromadb.PersistentClient(path=persist_directory)\n",
    "\n",
    "    try:\n",
    "        collection = client.get_collection(name=COLLECTION_NAME)\n",
    "        print(f\"Coleção '{COLLECTION_NAME}' já existe. Removendo para recriar...\")\n",
    "        client.delete_collection(name=COLLECTION_NAME)\n",
    "    except:\n",
    "        pass  # Collection doesn't exist, which is fine\n",
    "\n",
    "    print(f\"Criando nova coleção '{COLLECTION_NAME}'...\")\n",
    "    collection = client.create_collection(name=COLLECTION_NAME)\n",
    "\n",
    "    # Create document IDs\n",
    "    doc_ids = [f\"doc_{i}\" for i in range(len(documents))]\n",
    "    \n",
    "    # Add documents with metadata\n",
    "    collection.add(\n",
    "        documents=documents,\n",
    "        ids=doc_ids,\n",
    "        metadatas=metadatas\n",
    "    )\n",
    "    \n",
    "    # Update global variables\n",
    "    import vector_db\n",
    "    vector_db.client = client\n",
    "    vector_db.collection = collection\n",
    "    \n",
    "    print(f\"Banco de dados vetorial inicializado com {len(documents)} documentos com metadados.\")\n",
    "    return collection\n",
    "\n",
    "# --- Streamlit App ---\n",
    "st.set_page_config(page_title=\"ANEEL Chatbot\", page_icon=\":robot_face:\", layout=\"wide\")\n",
    "st.title(\"💬 Chatbot Inteligente de Leis da ANEEL (REN1000/2021)\")\n",
    "st.markdown(\"\"\"\n",
    "Bem-vindo(a)! Pergunte sobre a Resolução Normativa ANEEL nº 1000/2021.\n",
    "Este chatbot utiliza a Google Generative AI para responder às suas perguntas com base nos textos da lei.\n",
    "\"\"\")\n",
    "\n",
    "# --- Sidebar para Chave de API do Gemini e Status do Banco de Dados ---\n",
    "st.sidebar.header(\"Configurações\")\n",
    "api_key_input = st.sidebar.text_input(\n",
    "    \"Sua Chave de API Gemini (GOOGLE_API_KEY):\",\n",
    "    type=\"password\",\n",
    "    help=\"Obtenha sua chave em https://aistudio.google.com/app/apikey\"\n",
    ")\n",
    "\n",
    "# Determina qual chave usar (entrada do usuário tem prioridade)\n",
    "api_key = api_key_input or os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if api_key:\n",
    "    # Configura a chave no ambiente se foi fornecida via input\n",
    "    if api_key_input:\n",
    "        os.environ[\"GOOGLE_API_KEY\"] = api_key_input\n",
    "    \n",
    "    # Configura o cliente Gemini\n",
    "    try:\n",
    "        import google.generativeai as genai\n",
    "        genai.configure(api_key=api_key)\n",
    "        \n",
    "        if api_key_input:\n",
    "            st.sidebar.success(\"Chave de API configurada com sucesso! ✅\")\n",
    "        else:\n",
    "            st.sidebar.info(\"Chave de API já configurada no ambiente. ✅\")\n",
    "    except Exception as e:\n",
    "        st.sidebar.error(f\"Erro ao configurar a chave de API: {e}\")\n",
    "else:\n",
    "    st.sidebar.warning(\"Por favor, insira sua chave de API Gemini para continuar.\")\n",
    "    st.stop()\n",
    "\n",
    "# Verifica se o banco de dados vetorial está pronto antes de permitir consultas\n",
    "ensure_db_is_ready()\n",
    "\n",
    "# Inicializa o histórico de mensagens\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# Mostra o histórico de mensagens quando o app é recarregado\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "\n",
    "# Recebe a pergunta do usuário\n",
    "if prompt := st.chat_input(\"Qual a sua pergunta sobre a REN 1000/2021 da ANEEL?\"):\n",
    "    # Adiciona a pergunta ao histórico\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    # Exibe a pergunta na interface\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(prompt)\n",
    "    \n",
    "    # Mostra a resposta da IA em um container de mensagem\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        message_placeholder = st.empty()\n",
    "        message_placeholder.markdown(\"**Pensando...** 🧠\")\n",
    "\n",
    "        # 1. Consulta o banco de dados vetorial\n",
    "        retrieved_chunks = query_vector_db(prompt, n_results=3)\n",
    "        \n",
    "        if not retrieved_chunks:\n",
    "            full_response = \"Desculpe, não consegui encontrar informações relevantes nos documentos consultados para responder à sua pergunta.\"\n",
    "        else:\n",
    "            # 2. Gera a resposta usando o modelo Gemini\n",
    "            full_response = generate_response_with_gemini(prompt, retrieved_chunks)\n",
    "\n",
    "        # Atualiza a mensagem com a resposta final\n",
    "        message_placeholder.markdown(full_response)\n",
    "        \n",
    "        # Show sources with hierarchical information\n",
    "        with st.expander(\"Ver fontes e contexto\"):\n",
    "            # Get the last query results with metadata\n",
    "            if hasattr(st.session_state, 'last_query_results'):\n",
    "                results = st.session_state.last_query_results\n",
    "                for i, (doc, metadata) in enumerate(zip(results.get('documents', [[]])[0], results.get('metadatas', [[]])[0])):\n",
    "                    st.caption(f\"**Fonte {i+1}:**\")\n",
    "                    if metadata.get('full_hierarchical_path'):\n",
    "                        st.caption(f\"📍 **Localização:** {metadata['full_hierarchical_path']}\")\n",
    "                    st.caption(f\"📄 **Conteúdo:** {doc[:200]}...\")\n",
    "                    st.divider()\n",
    "            else:\n",
    "                for i, doc in enumerate(retrieved_chunks):\n",
    "                    st.caption(f\"**Fonte {i+1}:** {doc[:200]}...\")\n",
    "    \n",
    "    # Adiciona a resposta ao histórico\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5408f216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cleaned Text (first 500 characters) ---\n",
      "AGÊNCIA NACIONAL DE ENERGIA ELÉTRICA – ANEEL\n",
      "RESOLUÇÃO NORMATIVA ANEEL Nº 1.000, DE 7 DE DEZEMBRO DE 2021(*)\n",
      "Estabelece as Regras de Prestação do Serviço Público de Distribuição de Energia Elétrica; revoga as Resoluções Normativas ANEEL nº\n",
      "414\n",
      ", de 9 de setembro de 2010; nº\n",
      "470\n",
      ", de 13 de dezembro de 2011; nº\n",
      "901\n",
      ", de 8 de dezembro de 2020 e dá outras providências.\n",
      "Decisão Judicial\n",
      "Despacho 2.006/2024: Decisão Judicial - suspensos os efeitos referentes ao prazo de 60 (sessenta) ciclos estabeleci\n",
      "\n",
      "Cleaned text saved to '../data/cleaned_text.txt'.\n"
     ]
    }
   ],
   "source": [
    "# data_preprocess.py\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "\n",
    "ANEEL_RES_PATH = r\"../data/ren20211000.html\"\n",
    "ANEEL_RES_PATH_2 = r\"../data/ren20211000_2.html\"\n",
    "def fetch_html_content(url: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Faz uma requisição HTTP para obter o conteúdo HTML de uma URL.\n",
    "    :param url: URL do qual o conteúdo HTML será obtido.\n",
    "    :return: Conteúdo HTML como string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Verifica se a requisição foi bem-sucedida\n",
    "        \n",
    "        # Get encoding from response headers or detect it\n",
    "        if response.encoding is None or response.encoding == 'ISO-8859-1':\n",
    "            # Try to detect encoding from content\n",
    "            response.encoding = response.apparent_encoding\n",
    "        \n",
    "        # If still no proper encoding, default to utf-8\n",
    "        if response.encoding is None:\n",
    "            response.encoding = 'utf-8'\n",
    "            \n",
    "        return response.text\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Erro ao obter conteúdo HTML de {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def clean_html(html_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Lê um arquivo HTML, remove elementos com estilo `text-decoration: line-through` e extrai o texto limpo.\n",
    "    : param html_path: Caminho para o arquivo HTML a ser processado.\n",
    "    : return: Texto limpo extraído do HTML.\n",
    "    \"\"\"\n",
    "    with open(html_path, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'lxml')\n",
    "    \n",
    "    for strike in soup.find_all(style=re.compile('line-through')):\n",
    "        strike.decompose()\n",
    "    \n",
    "    # Extract clean text\n",
    "    return soup.get_text(separator='\\n', strip=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cleaned_text = clean_html(ANEEL_RES_PATH)\n",
    "    print(\"\\n--- Cleaned Text (first 500 characters) ---\")\n",
    "    print(cleaned_text[:500])\n",
    "\n",
    "    with open(r\"../data/cleaned_text.txt\", \"w\", encoding='utf-8') as output_file:\n",
    "        output_file.write(cleaned_text)\n",
    "    print(\"\\nCleaned text saved to '../data/cleaned_text.txt'.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cdc3039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Text Chunks (first 3 chunks) ---\n",
      "Chunk 1:\n",
      "AGÊNCIA NACIONAL DE ENERGIA ELÉTRICA – ANEEL\n",
      "RESOLUÇÃO NORMATIVA ANEEL Nº 1.000, DE 7 DE DEZEMBRO DE 2021(*)\n",
      "Estabelece as Regras de Prestação do Serviço Público de Distribuição de Energia Elétrica; revoga as Resoluções Normativas ANEEL nº\n",
      "414\n",
      ", de 9 de setembro de 2010; nº\n",
      "470\n",
      ", de 13 de dezembro de 2011; nº\n",
      "901\n",
      ", de 8 de dezembro de 2020 e dá outras providências.\n",
      "Decisão Judicial\n",
      "Despacho 2.006/2024: Decisão Judicial - suspensos os efeitos referentes ao prazo de 60 (sessenta) ciclos estabelecidos no inciso II do art. 323\n",
      ".\n",
      "Voto\n",
      "Texto Compilado\n",
      "O DIRETOR-GERAL DA AGÊNCIA NACIONAL DE ENERGIA ELÉTRICA – ANEEL, no uso de suas atribuições regimentais, de acordo com a deliberação da Diretoria, tendo em vista o disposto na Lei nº 9.427, de 26 de dezembro de 1996, no Decreto nº 2.335, de 6 de outubro de 1997 e o que consta do Processo nº 48500.005218/2020-06, resolve:\n",
      "TÍTULO I\n",
      "PARTE GERAL\n",
      "CAPÍTULO I\n",
      "DAS DISPOSIÇÕES GERAIS\n",
      "Seção I\n",
      "Do Objeto e Âmbito de Aplicação\n",
      "\n",
      "Chunk 2:\n",
      "TÍTULO I\n",
      "PARTE GERAL\n",
      "CAPÍTULO I\n",
      "DAS DISPOSIÇÕES GERAIS\n",
      "Seção I\n",
      "Do Objeto e Âmbito de Aplicação\n",
      "Art. 1º Esta Resolução Normativa estabelece as Regras de Prestação do Serviço Público de Distribuição de Energia Elétrica, nas quais estão dispostos os direitos e deveres do consumidor e demais usuários do serviço.\n",
      "§ 1º\n",
      "O disposto nesta Resolução aplica-se à concessionária e permissionária de serviço público de distribuição de energia elétrica e ao usuário do serviço, pessoa física ou jurídica que se beneficia ou utiliza, efetiva ou potencialmente, do serviço público, a exemplo de:\n",
      "I - consumidor;\n",
      "II - central geradora;\n",
      "III - distribuidora;\n",
      "IV - agente exportador; e\n",
      "V - agente importador.\n",
      "§ 2º\n",
      "A aplicação desta Resolução é complementada pelos Procedimentos de Distribuição de Energia Elétrica no Sistema Elétrico Nacional – PRODIST e pelos Procedimentos de Regulação Tarifária - PRORET.\n",
      "§ 3º\n",
      "\n",
      "Chunk 3:\n",
      "A aplicação desta Resolução é complementada pelos Procedimentos de Distribuição de Energia Elétrica no Sistema Elétrico Nacional – PRODIST e pelos Procedimentos de Regulação Tarifária - PRORET.\n",
      "§ 3º\n",
      "A aplicação desta Resolução não afasta a necessidade de cumprimento do disposto na regulação da ANEEL e na legislação, em especial:\n",
      "I - na Lei nº 8.078, de 11 de setembro de 1990, que instituiu o Código de Defesa do Consumidor e estabelece normas de proteção e defesa do consumidor, de ordem pública e interesse social; e\n",
      "II - na Lei nº 13.460, de 26 de junho de 2017, que dispõe sobre a participação, proteção e defesa dos direitos do usuário dos serviços públicos.\n",
      "§ 4º Aplica-se o disposto nesta Resolução, de forma subsidiária e complementar, ao consumidor e demais usuários que acessam o sistema de distribuição por meio de conexão às Demais Instalações de Transmissão – DIT, ou que possuam contratos celebrados com a distribuidora.\n",
      "Seção II\n",
      "Das Definições\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# text_processor.py\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_text(text: str, chunk_size: int=1000, chunk_overlap: int=200) -> list[str]:\n",
    "    \"\"\"\n",
    "    Divide o texto em pedaços menores com base no tamanho e na sobreposição especificados.\n",
    "    : param text: String de texto a ser dividido.\n",
    "    : param chunk_size: Tamanho máximo de cada pedaço de texto.\n",
    "    : param chunk_overlap: Número de caracteres que se sobrepõem entre pedaços consecutivos.\n",
    "    : return: Lista de pedaços de texto divididos.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        add_start_index=True\n",
    "    )\n",
    "    documents = text_splitter.create_documents([text])\n",
    "    return [doc.page_content for doc in documents]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with open(r\"../data/cleaned_text.txt\", \"r\", encoding='utf-8') as file:\n",
    "        cleaned_text = file.read()\n",
    "\n",
    "    chunks = split_text(cleaned_text, chunk_size=1000, chunk_overlap=200)\n",
    "    print(\"\\n--- Text Chunks (first 3 chunks) ---\")\n",
    "    for i, chunk in enumerate(chunks[:3]):\n",
    "        print(f\"Chunk {i+1}:\\n{chunk}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27a739a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coleção 'aneel_collection' carregada com sucesso.\n",
      "\n",
      "--- Vector Database Initialized ---\n",
      "\n",
      "Query: Quais são as principais mudanças na regulamentação de energia?\n",
      "\n",
      "Retrieved Documents:\n",
      "- Seção III\n",
      "Do Contrato de Compra de Energia Regulada – CCER\n",
      "Art. 162. O CCER deve conter as cláusulas gerais do art. 145 e, caso aplicáveis, as do art. 132, além de outras consideradas essenciais, observando as demais disposições deste Capítulo.\n",
      "Art. 163. O montante de energia elétrica contratado por...\n",
      "- Art. 29. O consumidor e demais usuários devem observar em suas instalações as normas e padrões da distribuidora, as normas da Associação Brasileira de Normas Técnicas - ABNT e as normas dos órgãos oficiais competentes, naquilo que for aplicável e não contrariar à regulação da ANEEL.\n",
      "Art. 30. O consu...\n"
     ]
    }
   ],
   "source": [
    "# vector_db.py\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "client  = None\n",
    "collection = None\n",
    "COLLECTION_NAME = \"aneel_collection\"\n",
    "\n",
    "def initialize_vector_db(documents: list[str], persist_directory: str=r\"../chroma_db_data\"):\n",
    "    \"\"\"\n",
    "    Inicializa o banco de dados vetorial ChromaDB com os documentos fornecidos.\n",
    "    O embedding de documentos é feito usando o modelo 'all-MiniLM-L6-v2'.\n",
    "    : param documents: Lista de documentos a serem armazenados no banco de dados.\n",
    "    : param persist_directory: Diretório onde o banco de dados será persistido.\n",
    "    : return: Instância do cliente ChromaDB e coleção criada.\n",
    "    \"\"\"\n",
    "    global client, collection\n",
    "    \n",
    "    client = chromadb.PersistentClient(path=persist_directory)\n",
    "\n",
    "    try:\n",
    "        collection = client.get_collection(name=COLLECTION_NAME)\n",
    "        print(f\"Coleção '{COLLECTION_NAME}' carregada com sucesso.\")\n",
    "    except:\n",
    "        print(f\"Coleção '{COLLECTION_NAME}' não encontrada. Criando nova coleção.\")\n",
    "        collection = client.create_collection(name=COLLECTION_NAME)\n",
    "        print(f\"Coleção '{COLLECTION_NAME}' criada com sucesso.\")\n",
    "\n",
    "        doc_ids = [f\"doc_{i}\" for i in range(len(documents))]\n",
    "        collection.add(\n",
    "            documents=documents,\n",
    "            ids=doc_ids,\n",
    "            metadatas=[{\"source\": f\"doc_{i}\"} for i in range(len(documents))],\n",
    "        )\n",
    "        print(f\"Banco de dados vetorial inicializado com {len(documents)} documentos.\")\n",
    "    \n",
    "    return collection\n",
    "\n",
    "def query_vector_db(query_text: str, n_results: int=5) -> list[str]:\n",
    "    \"\"\"\n",
    "    Consulta o banco de dados vetorial ChromaDB com uma string de consulta.\n",
    "    : param query_text: Texto da consulta para buscar documentos relevantes.\n",
    "    : param n_results: Número de resultados a serem retornados.\n",
    "    : return: Lista de IDs dos documentos mais relevantes encontrados.\n",
    "    \"\"\"\n",
    "    global collection\n",
    "    if not collection:\n",
    "        print(\"Erro: Coleção não inicializada. Por favor, chame initialize_vector_db primeiro.\")\n",
    "        try:\n",
    "            global client\n",
    "            client = chromadb.PersistentClient(path=r\"../chroma_db_data\")\n",
    "            collection = client.get_collection(name=COLLECTION_NAME)\n",
    "            print(f\"Coleção '{COLLECTION_NAME}' carregada com sucesso.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar a coleção: {e}\")\n",
    "            return []\n",
    "    \n",
    "    if not query_text:\n",
    "        return []\n",
    "    \n",
    "    results = collection.query(\n",
    "        query_texts=[query_text],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    return results['documents'][0]  if results and results['documents'] else []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with open(r\"../data/cleaned_text.txt\", \"r\", encoding='utf-8') as file:\n",
    "        cleaned_text = file.read()\n",
    "    \n",
    "    chunks = split_text(cleaned_text)\n",
    "    initialize_vector_db(chunks)\n",
    "    print(\"\\n--- Vector Database Initialized ---\")\n",
    "\n",
    "    if collection:\n",
    "        query = \"Quais são as principais mudanças na regulamentação de energia?\"\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        retrieved_docs = query_vector_db(query, n_results=2)\n",
    "        if retrieved_docs:\n",
    "            print(\"\\nRetrieved Documents:\")\n",
    "            for doc in retrieved_docs:\n",
    "                print(f\"- {doc[:300]}...\")\n",
    "        else:\n",
    "            print(\"Nenhum documento encontrado para a consulta.\")\n",
    "    else:\n",
    "        print(\"Falha ao inicializar a coleção. Verifique os logs para mais detalhes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a700c6be",
   "metadata": {},
   "source": [
    "General text: 500-1000 characters\n",
    "\n",
    "Technical docs: 300-800 characters\n",
    "\n",
    "Code: 200-500 characters (split at logical boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16dac854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved Documents:\n",
      "- Seção XI\n",
      "Do Período de Testes e Ajustes\n",
      "Art. 311. A distribuidora deve aplicar o período de testes para unidade consumidora para permitir a adequação da demanda contratada de consumo e a escolha da modalidade tarifária, nas seguintes situações: (\n",
      "Redação dada pela REN ANEEL 1.059, de 07.02.2023\n",
      ")\n",
      "I - início do fornecimento de energia elétrica;\n",
      "II - mudança para faturamento aplicável à unidade consumidora do grupo\n",
      "A, cuja opção anterior tenha sido por faturamento do grupo B;\n",
      "III - enquadramento na modalidade tarifária horária azul; e\n",
      "IV - acréscimo de demanda, quando maior que 5% da contratada.\n",
      "Parágrafo único. Quando do enquadramento na modalidade tarifária horária azul, o período de testes abrangerá exclusivamente o montante contratado para o posto tarifário ponta.\n",
      "Art. 312. O período de testes deve ter duração de 3 ciclos consecutivos e completos de faturamento.\n",
      "Parágrafo único.\n",
      "A distribuidora pode prorrogar o período de testes, mediante solicitação fundamentada do consumidor....\n",
      "- Art. 315. A distribuidora deve fornecer ao consumidor, sempre que solicitada, as informações necessárias à simulação do faturamento relacionadas ao período de testes.\n",
      "Art. 316. A distribuidora deve conceder para unidade consumidora do grupo A um período de ajustes no início do fornecimento de energia elétrica, para adequação do fator de potência, com duração de 3 ciclos consecutivos e completos de faturamento.\n",
      "§ 1º\n",
      "A distribuidora pode prorrogar o período de ajustes mediante solicitação fundamentada do consumidor.\n",
      "§ 2º\n",
      "A distribuidora deve calcular e informar ao consumidor os valores de energia elétrica e demanda de potência reativas excedentes durante o período de ajustes, sem efetuar a cobrança.\n",
      "Art. 317. A distribuidora pode iniciar o faturamento e, sendo aplicáveis, os períodos de testes e de ajustes,\n",
      "nas datas previstas no CUSD, devendo observar:\n",
      "I - as condições de suspensão de obra, de que trata o art. 89; e\n",
      "II - as condições de prorrogação do CUSD, de que trata o art. 157....\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs = query_vector_db(\"Qual é o periodo de testes para unidade consumidara?\", n_results=2)\n",
    "if retrieved_docs:\n",
    "    print(\"\\nRetrieved Documents:\")\n",
    "    for doc in retrieved_docs:\n",
    "        print(f\"- {doc}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f3185e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved Documents for Test Query:\n",
      "- § 3º A distribuidora deve disponibilizar a fatura de energia elétrica completa no espaço reservado de atendimento pela internet, independentemente da opção pelo resumo da fatura.\n",
      "Art. 329. A distribuidora deve prestar ao consumidor e demais usuários esclarecimentos sobre os tributos, subvenções e in...\n",
      "- VII - formalidades e exigências que sejam incompatíveis com a boa-fé, excessivamente onerosas ou cujo custo econômico ou social seja superior ao risco envolvido.\n",
      "Parágrafo único. No caso de núcleo urbano informal consolidado, nos termos da Lei nº 13.465, de 11 de julho de 2017, a comprovação de poss...\n",
      "\n",
      "--- Response from Gemini ---\n",
      "Todas as informações da primeira via, com destaque à expressão \"segunda via\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# chatbot_logic.py\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "try:\n",
    "    if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "        raise ValueError(\"A variável de ambiente GOOGLE_API_KEY não está definida.\")\n",
    "    genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "except ValueError as e:\n",
    "    print(f\"Erro de configuração: {e}. Garanta que a variável de ambiente GOOGLE_API_KEY esteja definida.\")\n",
    "\n",
    "def generate_response_with_gemini(query: str, context_chuncks: list[str]) -> str:\n",
    "    \"\"\"\n",
    "    Gera uma resposta usando o modelo Gemini da Google Generative AI, incorporando o contexto dos documentos recuperados.\n",
    "    : param query: Texto da consulta do usuário.\n",
    "    : param context_chuncks: Lista de pedaços de texto que fornecem contexto adicional para a resposta.\n",
    "    : return: Resposta gerada pelo modelo Gemini.\n",
    "    \"\"\"\n",
    "    if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "        raise ValueError(\"A variável de ambiente GOOGLE_API_KEY não está definida.\")\n",
    "    \n",
    "    # Prepara o contexto para a consulta\n",
    "    context_str = \"\\n\\n---\\n\\n\".join(context_chuncks)\n",
    "    prompt = f\"\"\"\n",
    "    Você é um assistente de IA especializado em leis e regulamentos brasileiros da ANEEL.\n",
    "    Sua tarefa é responder à pergunta do usuário com base estritamente nos trechos de lei fornecidos abaixo.\n",
    "    Não utilize conhecimento externo. Se a resposta não puder ser encontrada nos trechos fornecidos,\n",
    "    declare explicitamente que a informação não está disponível nos documentos consultados.\n",
    "    Seja conciso e direto ao ponto. Responda em português brasileiro.\n",
    "    \n",
    "    **Contexto (Trechos da Lei):**\n",
    "    {context_str}\n",
    "    \n",
    "    **Pergunta do Usuário:**\n",
    "    {query}\n",
    "\n",
    "**Sua Resposta:**\n",
    "\"\"\"\n",
    "    try:\n",
    "        model = genai.GenerativeModel(model_name=\"gemini-1.5-flash-8b\")\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao gerar resposta com Gemini: {e}\")\n",
    "        return \"Desculpe, ocorreu um erro ao processar sua consulta. Tente novamente mais tarde.\"\n",
    "\n",
    "test_user_query = \"O que deve constar na segunda via de fatura?\"\n",
    "retrieved_docs = query_vector_db(test_user_query, n_results=2)\n",
    "if retrieved_docs:\n",
    "    print(\"\\nRetrieved Documents for Test Query:\")\n",
    "    for doc in retrieved_docs:\n",
    "        print(f\"- {doc[:300]}...\")\n",
    "\n",
    "    response = generate_response_with_gemini(test_user_query, retrieved_docs)\n",
    "    print(\"\\n--- Response from Gemini ---\")\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
